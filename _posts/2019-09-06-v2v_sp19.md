---
layout: post
title:  "Vehicle to Vehicle Communication"
date:   2019-09-06 12:00:00 -0400
---

Project leader/Author: Timothy Liu \| Trey Fortmuller \| Amal Mehta \| Prom Putthisri \| Kallan Bao

<span class="image main"><img src="/../../images/projects/v2v/aruco.png" style="max-height: 500px; max-width: 500px;" alt="" /></span>

## Introduction

One potential application for drones is on the construction site. While they are already being used to survey plots of land and to catch any potential issues during construction, having drones actually build the structure is still at least several years off. Having multiple drones working together to perform tasks such as laying bricks or putting steel beams into place at can make constructing buildings much more efficient and much safer for workers as well.


## Project Description

The Vehicle to Vehicle Communication (V2V-Comm) project was designed to be a proof of concept to show that having drones actually assemble something on a construction site is feasible. We assembled a fleet of three drones with claws that can be used to pick up foam blocks and printed out a large grid of tags to help them navigate from one point to another.  


## Drone Customizations

Each of our drones is controlled by a Raspberry Pi board, with a Ubiquiti image installed. We decided to use Ubiquiti instead of the standard Raspian image since Ubiquiti came with ROS (Robot Operating System) out of the box and provided an easy way for us to work with a custom library called RosFlight. 

Since the drones needed a claw to pick up foam blocks, we had to design that ourselves as well, so a few extra modifications were needed so we could mount it onto the bottom of the drone. 

## Computer Vision

The grid we used for the drones to navigate through consisted of a 2D array of ArUco markers. Each ArUco marker is a bitmap that allows the drone to determine different markers apart, which allows us to determine the location on the grid each drone is at. It also allows us to determine the droneâ€™s orientation from the angle it sees the marker. Much of this functionality worked out of the box with OpenCV.

<span class="image main"><img src="/../../images/projects/v2v/aruco2.jpg" style="max-height: 500px; max-width: 500px;" alt="" /></span>

## Communication

In order to ensure that drones do not collide with one another while navigating through the grid, we used ROS to publish and listen to different information, such as where it is on the grid. The goal was to have each drone moving through the grid in a circle and if one drone stopped, then the drone behind it would be able to determine if it was getting too close, allowing it to take the appropriate action. 

## Looking Ahead

Much of the functionality to complete this project was finished over the course of the Spring 2019 semester. However due to time constraints, the claw could not be thoroughly tested in time and so we only had one claw for our three drones. 

The next steps for this project would be to finish building the claws and to build a simulation environment for our communication code to test our software. Once that has been completed, the actual drones will be ready to test.


<!--<div class="video-wrapper">
	<div class="video-responsive">
		<iframe width="560" height="315" src="https://www.youtube.com/embed/EP_dnBTCZg0?rel=0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
	</div>
</div>
-->

